{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \"\"\"\n",
    "        处理加载的训练数据DataFrame，去掉id，同时对signals以”，“进行拆分。\n",
    "    :param data: DataFrame, shape(n, 3)\n",
    "    :return: np array, shape(n, 206)\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(data.shape[0]):\n",
    "        x_res = data.iloc[i, 1].split(',')\n",
    "        label = data.iloc[i, 2]\n",
    "        x_res.append(label)\n",
    "        res.append(x_res)\n",
    "    return np.array(res, dtype=np.float64)\n",
    "\n",
    "\n",
    "def get_pred_x(data):\n",
    "    \"\"\"\n",
    "        处理需要预测数据的DataFrame\n",
    "    :param data: DataFrame, shape(n, 2)\n",
    "    :return: np array, shape(n, 205)\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(data.shape[0]):\n",
    "        x_res = data.iloc[i, 1].split(',')\n",
    "        res.append(x_res)\n",
    "    return np.array(res, dtype=np.float64)\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "        模型训练\n",
    "    :param dataloader: 训练数据集\n",
    "    :param model: 训练用到的模型\n",
    "    :param loss_fn: 评估用的损失函数\n",
    "    :param optimizer: 优化器\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch, x_y in enumerate(dataloader):\n",
    "        X, y = x_y[:, :205].type(torch.float64), torch.tensor(x_y[:, 205], dtype=torch.long, device='cuda:0')\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X.float())\n",
    "            loss = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"\n",
    "        模型测试部分\n",
    "    :param dataloader: 测试数据集\n",
    "    :param model: 测试模型\n",
    "    :param loss_fn: 损失函数\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct, l1_loss = 0, 0, 0\n",
    "    # 用来计算abs-sum. 等于PyTorch L1Loss\n",
    "    l1loss_fn = AbsSumLoss()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for x_y in dataloader:\n",
    "            X, y = x_y[:, :205].type(torch.float64), torch.tensor(x_y[:, 205], dtype=torch.long, device='cuda:0')\n",
    "            # Y用来计算L1 loss, y是CrossEntropy loss.\n",
    "            Y = torch.zeros(size=(len(y), 4), device='cuda:0')\n",
    "            for i in range(len(Y)):\n",
    "                Y[i][y[i]] = 1\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            l1_loss += l1loss_fn(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Results:\\nAccuracy: {(100 * correct):>0.1f}% abs-sum loss: {l1_loss:>8f} CroEtr loss: {test_loss:>8f}\")\n",
    "    \n",
    "def prediction(net):\n",
    "    \"\"\"\n",
    "        对数据进行预测\n",
    "    :param net: 训练好的模型\n",
    "    :param loss: 模型的测试误差值, 不是损失函数. 可以去掉, 这里是用来给预测数据命名方便区分.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        pred_loader = torch.utils.data.DataLoader(dataset=pred_data)\n",
    "        res = []\n",
    "        for x in pred_loader:\n",
    "            x = torch.tensor(x, device='cuda:0', dtype=torch.float64)\n",
    "            output = net(x.float())\n",
    "            res.append(output.cpu().numpy().tolist())\n",
    "\n",
    "        res = [i[0] for i in res]\n",
    "        res_df = pd.DataFrame(res, columns=['label_0', 'label_1', 'label_2', 'label_3'])\n",
    "        res_df.insert(0, 'id', value=range(100000, 120000))\n",
    "\n",
    "        res_df.to_csv('CNN-final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),  # 16, 1, 205\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=5, stride=4),     # 32, 1, 51\n",
    "        )\n",
    "\n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),  # 64, 1, 51\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_layer4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),                                 # 128, 1, 25\n",
    "        )\n",
    "\n",
    "        self.conv_layer5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_layer6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),                                  # 512, 1, 12\n",
    "        )\n",
    "\n",
    "        self.full_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=512 * 12, out_features=512 * 12),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512 * 12, out_features=512 * 12),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512 * 12, out_features=4)\n",
    "        )\n",
    "\n",
    "        self.pred_layer = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.conv_layer4(x)\n",
    "        x = self.conv_layer5(x)\n",
    "        x = self.conv_layer6(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.full_layer(x)\n",
    "\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.pred_layer(x)\n",
    "\n",
    "\n",
    "class AbsSumLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AbsSumLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss = F.l1_loss(target, output, reduction='sum')\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Epoch 1----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/admin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Accuracy: 96.9% abs-sum loss: 1470.799735 CroEtr loss: 0.776925\n",
      "training time:  24.30660605430603\n",
      "\n",
      "----------Epoch 2----------\n",
      "Test Results:\n",
      "Accuracy: 98.0% abs-sum loss: 1464.116916 CroEtr loss: 0.774103\n",
      "training time:  24.30437684059143\n",
      "\n",
      "----------Epoch 3----------\n",
      "Test Results:\n",
      "Accuracy: 98.6% abs-sum loss: 672.791228 CroEtr loss: 0.758702\n",
      "training time:  24.274587154388428\n",
      "\n",
      "----------Epoch 4----------\n",
      "Test Results:\n",
      "Accuracy: 98.6% abs-sum loss: 652.980903 CroEtr loss: 0.758540\n",
      "training time:  24.27287721633911\n",
      "\n",
      "----------Epoch 5----------\n",
      "Test Results:\n",
      "Accuracy: 98.7% abs-sum loss: 641.047783 CroEtr loss: 0.758088\n",
      "training time:  24.254902362823486\n",
      "\n",
      "----------Epoch 6----------\n",
      "Test Results:\n",
      "Accuracy: 98.4% abs-sum loss: 861.183906 CroEtr loss: 0.762327\n",
      "training time:  24.25239086151123\n",
      "\n",
      "----------Epoch 7----------\n",
      "Test Results:\n",
      "Accuracy: 99.1% abs-sum loss: 479.676681 CroEtr loss: 0.754162\n",
      "training time:  24.27400851249695\n",
      "\n",
      "----------Epoch 8----------\n",
      "Test Results:\n",
      "Accuracy: 99.0% abs-sum loss: 471.545245 CroEtr loss: 0.754279\n",
      "training time:  24.273009538650513\n",
      "\n",
      "----------Epoch 9----------\n",
      "Test Results:\n",
      "Accuracy: 99.1% abs-sum loss: 454.870470 CroEtr loss: 0.753899\n",
      "training time:  24.30091881752014\n",
      "\n",
      "----------Epoch 10----------\n",
      "Test Results:\n",
      "Accuracy: 99.2% abs-sum loss: 394.089019 CroEtr loss: 0.752406\n",
      "training time:  24.244264125823975\n",
      "\n",
      "----------Epoch 11----------\n",
      "Test Results:\n",
      "Accuracy: 99.1% abs-sum loss: 407.803830 CroEtr loss: 0.753011\n",
      "training time:  24.268249988555908\n",
      "\n",
      "----------Epoch 12----------\n",
      "Test Results:\n",
      "Accuracy: 98.8% abs-sum loss: 536.888768 CroEtr loss: 0.755917\n",
      "training time:  24.27231216430664\n",
      "\n",
      "----------Epoch 13----------\n",
      "Test Results:\n",
      "Accuracy: 99.2% abs-sum loss: 403.928142 CroEtr loss: 0.752852\n",
      "training time:  24.26219081878662\n",
      "\n",
      "----------Epoch 14----------\n",
      "Test Results:\n",
      "Accuracy: 99.2% abs-sum loss: 413.424403 CroEtr loss: 0.752959\n",
      "training time:  24.29148578643799\n",
      "\n",
      "----------Epoch 15----------\n",
      "Test Results:\n",
      "Accuracy: 99.2% abs-sum loss: 349.990831 CroEtr loss: 0.751813\n",
      "training time:  24.238000631332397\n",
      "\n",
      "----------Epoch 16----------\n",
      "Test Results:\n",
      "Accuracy: 99.1% abs-sum loss: 411.427310 CroEtr loss: 0.753131\n",
      "training time:  24.213627338409424\n",
      "\n",
      "----------Epoch 17----------\n",
      "Test Results:\n",
      "Accuracy: 99.3% abs-sum loss: 327.269016 CroEtr loss: 0.751128\n",
      "training time:  24.215279579162598\n",
      "\n",
      "----------Epoch 18----------\n",
      "Test Results:\n",
      "Accuracy: 99.3% abs-sum loss: 325.740852 CroEtr loss: 0.751181\n",
      "training time:  24.23430371284485\n",
      "\n",
      "----------Epoch 19----------\n",
      "Test Results:\n",
      "Accuracy: 99.2% abs-sum loss: 394.315973 CroEtr loss: 0.752677\n",
      "training time:  24.23321843147278\n",
      "\n",
      "----------Epoch 20----------\n",
      "Test Results:\n",
      "Accuracy: 99.3% abs-sum loss: 343.065095 CroEtr loss: 0.751550\n",
      "training time:  24.2285099029541\n",
      "\n",
      "----------Epoch 21----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 287.331923 CroEtr loss: 0.750309\n",
      "training time:  16.007420301437378\n",
      "\n",
      "----------Epoch 22----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 290.431644 CroEtr loss: 0.750377\n",
      "training time:  16.023038148880005\n",
      "\n",
      "----------Epoch 23----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 269.189714 CroEtr loss: 0.749931\n",
      "training time:  16.034618139266968\n",
      "\n",
      "----------Epoch 24----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 266.653300 CroEtr loss: 0.749901\n",
      "training time:  16.023033142089844\n",
      "\n",
      "----------Epoch 25----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 262.068980 CroEtr loss: 0.749796\n",
      "training time:  16.0292706489563\n",
      "\n",
      "----------Epoch 26----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 267.092164 CroEtr loss: 0.749924\n",
      "training time:  16.042423009872437\n",
      "\n",
      "----------Epoch 27----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 258.947885 CroEtr loss: 0.749731\n",
      "training time:  16.01395320892334\n",
      "\n",
      "----------Epoch 28----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 262.164439 CroEtr loss: 0.749801\n",
      "training time:  16.03266978263855\n",
      "\n",
      "----------Epoch 29----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 257.142521 CroEtr loss: 0.749703\n",
      "training time:  16.03069019317627\n",
      "\n",
      "----------Epoch 30----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 261.219883 CroEtr loss: 0.749805\n",
      "training time:  16.01932406425476\n",
      "\n",
      "----------Epoch 31----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 262.503051 CroEtr loss: 0.749826\n",
      "training time:  16.033985376358032\n",
      "\n",
      "----------Epoch 32----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 256.627460 CroEtr loss: 0.749708\n",
      "training time:  16.035662174224854\n",
      "\n",
      "----------Epoch 33----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 257.025290 CroEtr loss: 0.749720\n",
      "training time:  16.02932047843933\n",
      "\n",
      "----------Epoch 34----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 259.839404 CroEtr loss: 0.749797\n",
      "training time:  16.01901865005493\n",
      "\n",
      "----------Epoch 35----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 258.096927 CroEtr loss: 0.749745\n",
      "training time:  16.01704454421997\n",
      "\n",
      "----------Epoch 36----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 256.694231 CroEtr loss: 0.749731\n",
      "training time:  16.01845097541809\n",
      "\n",
      "----------Epoch 37----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 252.734916 CroEtr loss: 0.749646\n",
      "training time:  16.027310848236084\n",
      "\n",
      "----------Epoch 38----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 258.141129 CroEtr loss: 0.749767\n",
      "training time:  16.03700041770935\n",
      "\n",
      "----------Epoch 39----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 256.102342 CroEtr loss: 0.749721\n",
      "training time:  16.024344205856323\n",
      "\n",
      "----------Epoch 40----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 251.186355 CroEtr loss: 0.749609\n",
      "training time:  16.031986713409424\n",
      "\n",
      "----------Epoch 42----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.889013 CroEtr loss: 0.749530\n",
      "training time:  16.016047477722168\n",
      "\n",
      "----------Epoch 43----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 252.637607 CroEtr loss: 0.749636\n",
      "training time:  16.03150463104248\n",
      "\n",
      "----------Epoch 44----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 250.589177 CroEtr loss: 0.749594\n",
      "training time:  16.008895874023438\n",
      "\n",
      "----------Epoch 45----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 251.737145 CroEtr loss: 0.749621\n",
      "training time:  16.027382373809814\n",
      "\n",
      "----------Epoch 46----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 257.935711 CroEtr loss: 0.749765\n",
      "training time:  16.01861810684204\n",
      "\n",
      "----------Epoch 47----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 251.058128 CroEtr loss: 0.749604\n",
      "training time:  16.015466928482056\n",
      "\n",
      "----------Epoch 48----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.230179 CroEtr loss: 0.749537\n",
      "training time:  16.009203672409058\n",
      "\n",
      "----------Epoch 49----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 249.826428 CroEtr loss: 0.749587\n",
      "training time:  16.02653193473816\n",
      "\n",
      "----------Epoch 50----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 249.388630 CroEtr loss: 0.749576\n",
      "training time:  16.03080415725708\n",
      "\n",
      "----------Epoch 51----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.695269 CroEtr loss: 0.749544\n",
      "training time:  16.025274991989136\n",
      "\n",
      "----------Epoch 52----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 250.607998 CroEtr loss: 0.749619\n",
      "training time:  16.018909454345703\n",
      "\n",
      "----------Epoch 53----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 246.327493 CroEtr loss: 0.749531\n",
      "training time:  16.014125108718872\n",
      "\n",
      "----------Epoch 54----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 250.310562 CroEtr loss: 0.749588\n",
      "training time:  16.01710081100464\n",
      "\n",
      "----------Epoch 55----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 249.609833 CroEtr loss: 0.749600\n",
      "training time:  16.030062675476074\n",
      "\n",
      "----------Epoch 56----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.408539 CroEtr loss: 0.749536\n",
      "training time:  16.029179573059082\n",
      "\n",
      "----------Epoch 57----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 251.777056 CroEtr loss: 0.749654\n",
      "training time:  16.02377223968506\n",
      "\n",
      "----------Epoch 58----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 248.770971 CroEtr loss: 0.749562\n",
      "training time:  16.022706747055054\n",
      "\n",
      "----------Epoch 59----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.926847 CroEtr loss: 0.749564\n",
      "training time:  16.03598380088806\n",
      "\n",
      "----------Epoch 60----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 243.170794 CroEtr loss: 0.749457\n",
      "training time:  16.03200340270996\n",
      "\n",
      "----------Epoch 61----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 244.801919 CroEtr loss: 0.749500\n",
      "training time:  16.01472234725952\n",
      "\n",
      "----------Epoch 62----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 242.568338 CroEtr loss: 0.749442\n",
      "training time:  16.021031141281128\n",
      "\n",
      "----------Epoch 63----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 242.368447 CroEtr loss: 0.749434\n",
      "training time:  16.04092049598694\n",
      "\n",
      "----------Epoch 64----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.013668 CroEtr loss: 0.749540\n",
      "training time:  16.022894144058228\n",
      "\n",
      "----------Epoch 65----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.663808 CroEtr loss: 0.749554\n",
      "training time:  16.026498317718506\n",
      "\n",
      "----------Epoch 66----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 243.062401 CroEtr loss: 0.749467\n",
      "training time:  16.020657062530518\n",
      "\n",
      "----------Epoch 67----------\n",
      "Test Results:\n",
      "Accuracy: 99.5% abs-sum loss: 237.849789 CroEtr loss: 0.749337\n",
      "training time:  16.018207788467407\n",
      "\n",
      "----------Epoch 68----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 238.716420 CroEtr loss: 0.749367\n",
      "training time:  16.007586240768433\n",
      "\n",
      "----------Epoch 69----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 240.629037 CroEtr loss: 0.749411\n",
      "training time:  16.032402753829956\n",
      "\n",
      "----------Epoch 70----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 241.736991 CroEtr loss: 0.749429\n",
      "training time:  16.01881217956543\n",
      "\n",
      "----------Epoch 71----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 242.739437 CroEtr loss: 0.749453\n",
      "training time:  16.01862144470215\n",
      "\n",
      "----------Epoch 72----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.348057 CroEtr loss: 0.749569\n",
      "training time:  16.020604372024536\n",
      "\n",
      "----------Epoch 73----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 241.234638 CroEtr loss: 0.749424\n",
      "training time:  16.024006605148315\n",
      "\n",
      "----------Epoch 74----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 243.144738 CroEtr loss: 0.749475\n",
      "training time:  16.006929636001587\n",
      "\n",
      "----------Epoch 75----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 240.389077 CroEtr loss: 0.749400\n",
      "training time:  16.03460192680359\n",
      "\n",
      "----------Epoch 76----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 241.911123 CroEtr loss: 0.749450\n",
      "training time:  16.025967359542847\n",
      "\n",
      "----------Epoch 77----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 239.393194 CroEtr loss: 0.749387\n",
      "training time:  16.03319764137268\n",
      "\n",
      "----------Epoch 78----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 239.343129 CroEtr loss: 0.749386\n",
      "training time:  16.023476123809814\n",
      "\n",
      "----------Epoch 79----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 238.851314 CroEtr loss: 0.749365\n",
      "training time:  16.028019666671753\n",
      "\n",
      "----------Epoch 80----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 245.189936 CroEtr loss: 0.749531\n",
      "training time:  16.031041622161865\n",
      "\n",
      "----------Epoch 81----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 242.249629 CroEtr loss: 0.749446\n",
      "training time:  16.023622512817383\n",
      "\n",
      "----------Epoch 82----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 247.686123 CroEtr loss: 0.749582\n",
      "training time:  16.02859878540039\n",
      "\n",
      "----------Epoch 83----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 239.345767 CroEtr loss: 0.749355\n",
      "training time:  16.016261100769043\n",
      "\n",
      "----------Epoch 84----------\n",
      "Test Results:\n",
      "Accuracy: 99.5% abs-sum loss: 238.430112 CroEtr loss: 0.749358\n",
      "training time:  16.029036283493042\n",
      "\n",
      "----------Epoch 85----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 243.644005 CroEtr loss: 0.749482\n",
      "training time:  16.02175784111023\n",
      "\n",
      "----------Epoch 86----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 241.698754 CroEtr loss: 0.749453\n",
      "training time:  16.02583646774292\n",
      "\n",
      "----------Epoch 87----------\n",
      "Test Results:\n",
      "Accuracy: 99.5% abs-sum loss: 239.920757 CroEtr loss: 0.749399\n",
      "training time:  16.02175283432007\n",
      "\n",
      "----------Epoch 88----------\n",
      "Test Results:\n",
      "Accuracy: 99.5% abs-sum loss: 237.239629 CroEtr loss: 0.749328\n",
      "training time:  16.021050930023193\n",
      "\n",
      "----------Epoch 89----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 240.553933 CroEtr loss: 0.749402\n",
      "training time:  16.025420427322388\n",
      "\n",
      "----------Epoch 90----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 240.903097 CroEtr loss: 0.749424\n",
      "training time:  16.013943910598755\n",
      "\n",
      "----------Epoch 91----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 241.189170 CroEtr loss: 0.749437\n",
      "training time:  16.01982808113098\n",
      "\n",
      "----------Epoch 92----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 242.499712 CroEtr loss: 0.749458\n",
      "training time:  16.014410257339478\n",
      "\n",
      "----------Epoch 93----------\n",
      "Test Results:\n",
      "Accuracy: 99.5% abs-sum loss: 242.266770 CroEtr loss: 0.749442\n",
      "training time:  16.020562171936035\n",
      "\n",
      "----------Epoch 94----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 240.114954 CroEtr loss: 0.749399\n",
      "training time:  16.01817297935486\n",
      "\n",
      "----------Epoch 95----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 238.271281 CroEtr loss: 0.749355\n",
      "training time:  16.030113220214844\n",
      "\n",
      "----------Epoch 96----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 238.107108 CroEtr loss: 0.749346\n",
      "training time:  16.038002490997314\n",
      "\n",
      "----------Epoch 97----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 236.307633 CroEtr loss: 0.749317\n",
      "training time:  16.017287254333496\n",
      "\n",
      "----------Epoch 98----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 241.563361 CroEtr loss: 0.749448\n",
      "training time:  16.010202646255493\n",
      "\n",
      "----------Epoch 99----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 237.666795 CroEtr loss: 0.749353\n",
      "training time:  16.049124002456665\n",
      "\n",
      "----------Epoch 100----------\n",
      "Test Results:\n",
      "Accuracy: 99.4% abs-sum loss: 240.071302 CroEtr loss: 0.749410\n",
      "training time:  16.012349128723145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 加载数据集\n",
    "    data = pd.read_csv('train.csv')\n",
    "    data = process_data(data)\n",
    "    pred_data = pd.read_csv('testA.csv')\n",
    "    pred_data = get_pred_x(pred_data)\n",
    "\n",
    "    # 初始化模型\n",
    "    adm_lr = 1e-4\n",
    "    sgd_lr = 5e-6\n",
    "    mom = 0.8\n",
    "    w_decay = 1e-5\n",
    "    n_epoch = 100\n",
    "    b_size = 64\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    net = Model()\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=adm_lr, weight_decay=w_decay, amsgrad=True)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    # 拆分训练测试集\n",
    "    train, test = train_test_split(data, test_size=0.2)\n",
    "    train, test = torch.cuda.FloatTensor(train), torch.cuda.FloatTensor(test)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=b_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=b_size)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch == 20:\n",
    "            optimizer = torch.optim.SGD(params=net.parameters(), lr=sgd_lr, weight_decay=w_decay, momentum=mom)\n",
    "        start = time.time()\n",
    "        print(f\"\\n----------Epoch {epoch + 1}----------\")\n",
    "        train_loop(train_loader, net, loss_fn, optimizer)\n",
    "        test_loop(test_loader, net, loss_fn)\n",
    "        end = time.time()\n",
    "        print('training time: ', end - start)\n",
    "\n",
    "    prediction(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
